{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e7e386-ba45-4686-8ce7-251f40f232d9",
   "metadata": {},
   "source": [
    "# Neural Networks Commonly Used In Data Science\n",
    "\n",
    "### A Breakdown of the artificial neural networks used in data science, their applications and examples of use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537dc673-8a59-4245-adfa-5f98df1e69bd",
   "metadata": {},
   "source": [
    "## Understanding Modern Neural Network Architectures in Data Science\n",
    "\n",
    "A lot could be said about how artificial neural networks (ANNs) have revolutionized the field of machine learning and data science, and how they are enabling breakthroughs in areas ranging from image recognition and natural language processing to autonomous systems and drug discovery. We could even start off discussing the origins being inspired by the biological neural networks in our human brains, then move into a neato discussion of how these computational models have evolved into various specialized architectures and how they are each designed to excel at specific types of tasks. Awesome. Wow.\n",
    "\n",
    "Not discounting any of that, and not that I don't have an appreciation for it, but as this notebook is primarily for my own purposes, I'll spare myself the pedantic bullshit and just get into the things that matter in practice. Self, you're welcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c87947-368e-4b79-8d12-b87793b7e556",
   "metadata": {},
   "source": [
    "## Neural Networks' Role In Data Science\n",
    "\n",
    "Since \"big data\" is thing, we data scientists face increasingly complex challenges in extracting meaningful patterns and insights from the vast amounts of structured and unstructured data. Neural networks have emerged as powerful tools to have in the ol' toolkit since they offer sophisticated solutions for things like:\n",
    "\n",
    "- Pattern Recognition: Identifying complex patterns in large datasets that traditional statistical methods could miss.\n",
    "- Feature Learning: Automatically discovering relevant features in raw data, reducing the need for manual feature engineering.\n",
    "- Predictive Modeling: Creating highly accurate models for both regression and classification tasks.\n",
    "- Data Generation: Synthesizing new data that shares characteristics with training examples.\n",
    "- Dimensionality Reduction: Compressing high-dimensional data while preserving important information.\n",
    "\n",
    "This notebook will have a self-serving purpose in that I will explore six fundamental neural network architectures that form the backbone of many modern data science applications so that I have a reference (I can't bring everything from work into my personal space, you know). The six I want to cover here are:\n",
    "\n",
    "1. Feedforward Neural Networks (FNN): The classical architecture that started it all.\n",
    "2. Convolutional Neural Networks (CNN): Masters of visual pattern recognition.\n",
    "3. Recurrent Neural Networks (RNN): Specialists in sequential data processing.\n",
    "4. Long Short-Term Memory Networks (LSTM): Advanced networks for long-term dependencies.\n",
    "5. Autoencoders: Unsupervised learning powerhouses for dimensionality reduction.\n",
    "6. Generative Adversarial Networks (GAN): Creative networks that can generate new data.\n",
    "\n",
    "Each architecture brings its own strengths and specialized applications, so understanding their fundamental principles is crucial for working in the field of deep learning. This is why I will be spend a brief moment for each architecture to explain their structure, use cases, and what makes them unique in the neural network family."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917feb72-563f-4bba-a2fa-2fa2931cd847",
   "metadata": {},
   "source": [
    "## Well, what the hell am I waiting for? Let's get to it.\n",
    "\n",
    "Start where you want:\n",
    "1. [Feedforward Neural Networks (FNN)](Feedforward_Neural_Networks.ipynb)\n",
    "2. [Convolutional Neural Networks (CNN)](Convolutional_Neural_Networks.ipynb)\n",
    "3. [Recurrent Neural Networks (RNN)](Recurrent_Neural_Networks.ipynb)\n",
    "4. [Long Short-Term Memory Networks (LSTM)](.ipynb)\n",
    "5. [Autoencoders](Autoencoders.ipynb)\n",
    "6. [Generative Adversarial Networks (GAN)](Generative_Adversarial_Networks.ipynb)\n",
    "\n",
    "Each notebook I have created will be strucutred, basically, the same way: Start off with the gist what that type neural netowrok is and what problems to use it for, a short list of publicly available datasets to apply the it to (most are well known by practitioners), then a few impementations using some of those datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
